{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9aa284d",
   "metadata": {},
   "source": [
    "# LR/CNN baseline training + evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9ee6a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import os, sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3bff8524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CWD: /Users/yujincha/Documents/snu_ms/coursework/2025-2/M1522.003300 모바일 및 유비쿼터스 컴퓨팅 (이영기, Graduate)/mini-project/notebooks\n",
      "sys.path first entries:\n",
      "/Users/yujincha/Documents/snu_ms/coursework/2025-2/M1522.003300 모바일 및 유비쿼터스 컴퓨팅 (이영기, Graduate)/mini-project\n",
      "/Users/yujincha/Documents/snu_ms/coursework/2025-2/M1522.003300 모바일 및 유비쿼터스 컴퓨팅 (이영기, Graduate)/mini-project/src\n",
      "/Users/yujincha/miniforge3/envs/har-ldp/lib/python310.zip\n",
      "/Users/yujincha/miniforge3/envs/har-ldp/lib/python3.10\n",
      "/Users/yujincha/miniforge3/envs/har-ldp/lib/python3.10/lib-dynload\n"
     ]
    }
   ],
   "source": [
    "project_root = os.path.abspath(\"..\")  # mini-project root\n",
    "src_root = os.path.join(project_root, \"src\")\n",
    "\n",
    "# 1) Remove any existing occurrences\n",
    "sys.path = [p for p in sys.path if p not in (project_root, src_root)]\n",
    "\n",
    "# 2) Insert project paths at the very front\n",
    "sys.path.insert(0, project_root)\n",
    "sys.path.insert(1, src_root)  # not strictly needed, but fine\n",
    "\n",
    "print(\"CWD:\", os.getcwd())\n",
    "print(\"sys.path first entries:\")\n",
    "print(\"\\n\".join(sys.path[:5]))\n",
    "\n",
    "if \"src\" in sys.modules:\n",
    "    del sys.modules[\"src\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea1d0599",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src.__file__: /Users/yujincha/Documents/snu_ms/coursework/2025-2/M1522.003300 모바일 및 유비쿼터스 컴퓨팅 (이영기, Graduate)/mini-project/src/__init__.py\n"
     ]
    }
   ],
   "source": [
    "import src\n",
    "print(\"src.__file__:\", src.__file__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "302070d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import set_seed, get_device\n",
    "from src.data import load_har, make_train_val_test, make_dataloaders\n",
    "from src.models import LRBaseline, SmallCNN\n",
    "from src.train import train_classifier, evaluate_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d4ddfde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n",
      "dataset_dir: ../data/UCI_HAR_Dataset\n",
      "Sample batch shape: torch.Size([128, 1, 561])\n",
      "Epoch 01: train_loss=1.4712, train_acc=0.3038, val_loss=1.0958, val_acc=0.3932\n",
      "Epoch 02: train_loss=1.0835, train_acc=0.4064, val_loss=1.0617, val_acc=0.4014\n",
      "Epoch 03: train_loss=1.0661, train_acc=0.4138, val_loss=1.0559, val_acc=0.3918\n",
      "Epoch 04: train_loss=1.0681, train_acc=0.4076, val_loss=1.0535, val_acc=0.3932\n",
      "Epoch 05: train_loss=1.0543, train_acc=0.4333, val_loss=1.0686, val_acc=0.3728\n",
      "Epoch 06: train_loss=1.0470, train_acc=0.4381, val_loss=1.0386, val_acc=0.4653\n",
      "Epoch 07: train_loss=1.0334, train_acc=0.4576, val_loss=1.0336, val_acc=0.4735\n",
      "Epoch 08: train_loss=1.0084, train_acc=0.5040, val_loss=0.9885, val_acc=0.4952\n",
      "Epoch 09: train_loss=0.9778, train_acc=0.5330, val_loss=0.9437, val_acc=0.5673\n",
      "Epoch 10: train_loss=0.9177, train_acc=0.5782, val_loss=0.9105, val_acc=0.5034\n",
      "Epoch 11: train_loss=0.8645, train_acc=0.6050, val_loss=0.8234, val_acc=0.6259\n",
      "Epoch 12: train_loss=0.7926, train_acc=0.6417, val_loss=0.7916, val_acc=0.5741\n",
      "Epoch 13: train_loss=0.7490, train_acc=0.6509, val_loss=0.8403, val_acc=0.5728\n",
      "Epoch 14: train_loss=0.7234, train_acc=0.6704, val_loss=0.6722, val_acc=0.6952\n",
      "Epoch 15: train_loss=0.6884, train_acc=0.6884, val_loss=0.6510, val_acc=0.6952\n",
      "Epoch 16: train_loss=0.6709, train_acc=0.6965, val_loss=0.6318, val_acc=0.7293\n",
      "Epoch 17: train_loss=0.6654, train_acc=0.6940, val_loss=0.6223, val_acc=0.7374\n",
      "Epoch 18: train_loss=0.6733, train_acc=0.6890, val_loss=0.6415, val_acc=0.6830\n",
      "Epoch 19: train_loss=0.6496, train_acc=0.7003, val_loss=0.6637, val_acc=0.6612\n",
      "Epoch 20: train_loss=0.6222, train_acc=0.7245, val_loss=0.6397, val_acc=0.6857\n",
      "[CNN] Test loss=0.7236, Test acc=0.6681\n"
     ]
    }
   ],
   "source": [
    "def run_lr_baseline(data_root=\"./data\"):\n",
    "    set_seed(42)\n",
    "    device = get_device()\n",
    "    print(\"Device:\", device)\n",
    "\n",
    "    X_train, y_train, X_test, y_test = load_har(data_root)\n",
    "    (X_tr, y_tr), (X_val, y_val), (X_te, y_te) = make_train_val_test(\n",
    "        X_train, y_train, X_test, y_test, val_ratio=0.1, seed=42\n",
    "    )\n",
    "\n",
    "    train_loader, val_loader, test_loader = make_dataloaders(\n",
    "        X_tr, y_tr, X_val, y_val, X_te, y_te, batch_size=128\n",
    "    )\n",
    "\n",
    "    input_dim = X_tr.shape[1]\n",
    "    num_classes = int(y_train.max() + 1)\n",
    "\n",
    "    model = LRBaseline(input_dim=input_dim, num_classes=num_classes)\n",
    "    history = train_classifier(\n",
    "        model, train_loader, val_loader, device,\n",
    "        epochs=20, lr=1e-3\n",
    "    )\n",
    "\n",
    "    test_loss, test_acc = evaluate_classifier(model, test_loader, device)\n",
    "    print(f\"[LR] Test loss={test_loss:.4f}, Test acc={test_acc:.4f}\")\n",
    "\n",
    "\n",
    "def run_cnn_baseline(data_root=\"../data\"):\n",
    "    set_seed(42)\n",
    "    device = get_device()\n",
    "    print(\"Device:\", device)\n",
    "\n",
    "    X_train, y_train, X_test, y_test = load_har(data_root)\n",
    "    (X_tr, y_tr), (X_val, y_val), (X_te, y_te) = make_train_val_test(\n",
    "        X_train, y_train, X_test, y_test, val_ratio=0.1, seed=42\n",
    "    )\n",
    "\n",
    "    train_loader, val_loader, test_loader = make_dataloaders(\n",
    "        X_tr, y_tr, X_val, y_val, X_te, y_te, batch_size=128\n",
    "    )\n",
    "\n",
    "    # Inspect one batch to confirm shape\n",
    "    sample_X, _ = next(iter(train_loader))\n",
    "    print(\"Sample batch shape:\", sample_X.shape)   # should be (B, 1, 561)\n",
    "    in_channels = sample_X.shape[1]\n",
    "    num_classes = int(y_train.max() + 1)\n",
    "\n",
    "    model = SmallCNN(in_channels=in_channels, num_classes=num_classes)\n",
    "\n",
    "    history = train_classifier(\n",
    "        model, train_loader, val_loader, device,\n",
    "        epochs=20, lr=1e-3\n",
    "    )\n",
    "\n",
    "    test_loss, test_acc = evaluate_classifier(model, test_loader, device)\n",
    "    print(f\"[CNN] Test loss={test_loss:.4f}, Test acc={test_acc:.4f}\")\n",
    "    return history, (test_loss, test_acc)\n",
    "\n",
    "\n",
    "cnn_hist, cnn_metrics = run_cnn_baseline()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "har-ldp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
